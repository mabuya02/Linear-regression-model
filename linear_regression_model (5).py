# -*- coding: utf-8 -*-
"""linear_regression_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uHd69SsnTjA7wowZjcGS6lhFCQ5peCq7
"""

import tensorflow as tf

import numpy as np
import pandas as pd
import yfinance as yf
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.impute import SimpleImputer
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import PolynomialFeatures

from google.colab import drive
drive.mount('/content/drive')

file_path = '/content/drive/MyDrive/NSE_dataset/NSE_data_all_stocks_2016.csv'
stock_data = pd.read_csv(file_path)

stock_data.isnull().sum()

print(stock_data.dtypes)

encoded_data = pd.get_dummies(stock_data, columns=['CODE', 'NAME'])

numerical_features = ['12m Low', '12m High', 'Day Low', 'Day High', 'Volume']
# Replace '-' with NaN
stock_data[numerical_features] = stock_data[numerical_features].replace('-', np.nan)

# Remove commas and '%' symbol, and convert to numeric
stock_data[numerical_features] = stock_data[numerical_features].replace({',': '', '%': ''}, regex=True).astype(float)

# Outlier detection and handling
for column in numerical_features:
    # Calculate the IQR for the column
    Q1 = stock_data[column].quantile(0.25)
    Q3 = stock_data[column].quantile(0.75)
    IQR = Q3 - Q1

    # Detect outliers as values outside of the range [Q1 - 1.5 * IQR, Q3 + 1.5 * IQR]
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Replace outliers with NaN
    stock_data[column] = np.where(
        (stock_data[column] < lower_bound) | (stock_data[column] > upper_bound),
        np.nan,
        stock_data[column]
    )

# Standardization
scaler = StandardScaler()
for column in numerical_features:
    stock_data[column + '_scaled'] = scaler.fit_transform(stock_data[[column]])

# Normalization
scaler = MinMaxScaler()
for column in numerical_features:
    stock_data[column + '_normalized'] = scaler.fit_transform(stock_data[[column]])

selected_features = ['12m Low', '12m High', 'Day Low', 'Day High', 'Volume']
target_variable = 'Day Price'
data = stock_data[selected_features + [target_variable]].dropna()

X = data[selected_features]
y = data[target_variable]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

poly_transform = PolynomialFeatures(degree=2)  # Adjust the degree as needed
X_train_poly = poly_transform.fit_transform(X_train)
X_test_poly = poly_transform.transform(X_test)

model = LinearRegression()
model.fit(X_train_poly, y_train)

y_pred = model.predict(X_test_poly)

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error (MSE):", mse)
print("Root Mean Squared Error (RMSE):", rmse)
print("Mean Absolute Error (MAE):", mae)
print("R-squared (R2):", r2)

# Assuming you have already trained your model and have X_test_poly and y_test

# Make predictions on the test data
y_pred = model.predict(X_test_poly)

# Set the figure size
plt.figure(figsize=(8, 6))

# Plot the scatter plot of predicted values against actual values
plt.scatter(pd.to_numeric(y_test), y_pred, s=50, alpha=0.8)

# Add a regression line
plt.plot([pd.to_numeric(y_test).min(), pd.to_numeric(y_test).max()], [pd.to_numeric(y_test).min(), pd.to_numeric(y_test).max()], 'k--', lw=2)

plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Actual vs. Predicted Values')
plt.grid(True)

# Adjust the x-axis and y-axis limits
plt.xlim([pd.to_numeric(y_test).min() - 5, pd.to_numeric(y_test).max() + 5])
plt.ylim([y_pred.min() - 5, y_pred.max() + 5])

plt.tight_layout()
plt.show()